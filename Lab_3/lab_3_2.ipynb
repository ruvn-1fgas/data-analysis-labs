{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c439c55",
   "metadata": {
    "papermill": {
     "duration": 0.006939,
     "end_time": "2023-10-18T07:35:23.518288",
     "exception": false,
     "start_time": "2023-10-18T07:35:23.511349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Лабораторная работа №3 - Store Sales - Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7e9b7",
   "metadata": {},
   "source": [
    "### Импорт либ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d34269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:44.802510Z",
     "iopub.status.busy": "2023-10-18T07:35:44.802138Z",
     "iopub.status.idle": "2023-10-18T07:35:46.996318Z",
     "shell.execute_reply": "2023-10-18T07:35:46.995317Z"
    },
    "papermill": {
     "duration": 2.207987,
     "end_time": "2023-10-18T07:35:46.998595",
     "exception": false,
     "start_time": "2023-10-18T07:35:44.790608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/store-sales-time-series-forecasting/train_1.csv\n",
      "../input/store-sales-time-series-forecasting/oil.csv\n",
      "../input/store-sales-time-series-forecasting/test.csv\n",
      "../input/store-sales-time-series-forecasting/sample_submission.csv\n",
      "../input/store-sales-time-series-forecasting/100_score.csv\n",
      "../input/store-sales-time-series-forecasting/train_2.csv\n",
      "../input/store-sales-time-series-forecasting/stores.csv\n",
      "../input/store-sales-time-series-forecasting/holidays_events.csv\n",
      "../input/store-sales-time-series-forecasting/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from darts import TimeSeries\n",
    "\n",
    "input_path = \"../input/store-sales-time-series-forecasting\"\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(input_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419633d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:47.019940Z",
     "iopub.status.busy": "2023-10-18T07:35:47.019416Z",
     "iopub.status.idle": "2023-10-18T07:35:50.824151Z",
     "shell.execute_reply": "2023-10-18T07:35:50.822900Z"
    },
    "papermill": {
     "duration": 3.818067,
     "end_time": "2023-10-18T07:35:50.826514",
     "exception": false,
     "start_time": "2023-10-18T07:35:47.008447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr      family  sales  onpromotion\n",
       "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1 2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2 2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3 2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4 2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 mb per file - cringe\n",
    "train_1_part = pd.read_csv(f\"{input_path}/train_1.csv\", parse_dates=['date'])\n",
    "train_2_part = pd.read_csv(f\"{input_path}/train_2.csv\", parse_dates=['date'])\n",
    "train_data = pd.concat([train_1_part, train_2_part])\n",
    "\n",
    "test_data = pd.read_csv(f\"{input_path}/test.csv\", parse_dates=['date'])\n",
    "oil = pd.read_csv(f\"{input_path}/oil.csv\", parse_dates=['date'])\n",
    "holiday_events = pd.read_csv(f\"{input_path}/holidays_events.csv\", parse_dates=['date'])\n",
    "stores = pd.read_csv(f\"{input_path}/stores.csv\")\n",
    "transcations = pd.read_csv(f\"{input_path}/transactions.csv\", parse_dates=['date'])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b12a29c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:58.376397Z",
     "iopub.status.busy": "2023-10-18T07:35:58.376048Z",
     "iopub.status.idle": "2023-10-18T07:35:58.546892Z",
     "shell.execute_reply": "2023-10-18T07:35:58.545863Z"
    },
    "papermill": {
     "duration": 0.18525,
     "end_time": "2023-10-18T07:35:58.549070",
     "exception": false,
     "start_time": "2023-10-18T07:35:58.363820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', 'BOOKS',\n",
       "       'BREAD/BAKERY', 'CELEBRATION', 'CLEANING', 'DAIRY', 'DELI', 'EGGS',\n",
       "       'FROZEN FOODS', 'GROCERY I', 'GROCERY II', 'HARDWARE',\n",
       "       'HOME AND KITCHEN I', 'HOME AND KITCHEN II', 'HOME APPLIANCES',\n",
       "       'HOME CARE', 'LADIESWEAR', 'LAWN AND GARDEN', 'LINGERIE',\n",
       "       'LIQUOR,WINE,BEER', 'MAGAZINES', 'MEATS', 'PERSONAL CARE',\n",
       "       'PET SUPPLIES', 'PLAYERS AND ELECTRONICS', 'POULTRY',\n",
       "       'PREPARED FOODS', 'PRODUCE', 'SCHOOL AND OFFICE SUPPLIES',\n",
       "       'SEAFOOD'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Список типов товаров\n",
    "family_list = train_data['family'].unique()\n",
    "family_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e5d95",
   "metadata": {
    "papermill": {
     "duration": 0.009711,
     "end_time": "2023-10-18T07:35:50.888791",
     "exception": false,
     "start_time": "2023-10-18T07:35:50.879080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aba515",
   "metadata": {
    "papermill": {
     "duration": 0.009399,
     "end_time": "2023-10-18T07:35:50.927254",
     "exception": false,
     "start_time": "2023-10-18T07:35:50.917855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Целевые и статик данные\n",
    "\n",
    "Цели - 'sales' (продажи)\\\n",
    "Статик: \\\n",
    "'city'      - город, в котором находится магазин\\\n",
    "'state'     - штат, в котором находится магазин\\\n",
    "'type'      - тип продаваемых товаров\\\n",
    "'cluster'   - группа похожих магазинов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21167fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:50.948212Z",
     "iopub.status.busy": "2023-10-18T07:35:50.947846Z",
     "iopub.status.idle": "2023-10-18T07:35:52.401843Z",
     "shell.execute_reply": "2023-10-18T07:35:52.400784Z"
    },
    "papermill": {
     "duration": 1.467023,
     "end_time": "2023-10-18T07:35:52.404095",
     "exception": false,
     "start_time": "2023-10-18T07:35:50.937072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  store_nbr      family  sales  onpromotion   city      state  \\\n",
       "date                                                                          \n",
       "2013-01-01   0          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
       "2013-01-01   1          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
       "2013-01-01   2          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
       "2013-01-01   3          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
       "2013-01-01   4          1       BOOKS    0.0            0  Quito  Pichincha   \n",
       "\n",
       "           type  cluster  \n",
       "date                      \n",
       "2013-01-01    D       13  \n",
       "2013-01-01    D       13  \n",
       "2013-01-01    D       13  \n",
       "2013-01-01    D       13  \n",
       "2013-01-01    D       13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_merged = pd.merge(train_data, stores, on='store_nbr').set_index('date')\n",
    "static_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf607d2",
   "metadata": {
    "papermill": {
     "duration": 0.009743,
     "end_time": "2023-10-18T07:35:52.424166",
     "exception": false,
     "start_time": "2023-10-18T07:35:52.414423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Изменяемые данные\n",
    "Данные, меняющиеся во времени\\\n",
    "День, день недели, месяц и т.д.\n",
    "\n",
    "Цена на бензин, праздники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69853fd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:52.446479Z",
     "iopub.status.busy": "2023-10-18T07:35:52.445649Z",
     "iopub.status.idle": "2023-10-18T07:35:54.471528Z",
     "shell.execute_reply": "2023-10-18T07:35:54.470259Z"
    },
    "papermill": {
     "duration": 2.039852,
     "end_time": "2023-10-18T07:35:54.474118",
     "exception": false,
     "start_time": "2023-10-18T07:35:52.434266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  store_nbr      family  sales  onpromotion  dcoilwtico  day  \\\n",
       "date                                                                         \n",
       "2013-01-01   0          1  AUTOMOTIVE    0.0            0         NaN    1   \n",
       "2013-01-01   1          1   BABY CARE    0.0            0         NaN    1   \n",
       "2013-01-01   2          1      BEAUTY    0.0            0         NaN    1   \n",
       "2013-01-01   3          1   BEVERAGES    0.0            0         NaN    1   \n",
       "2013-01-01   4          1       BOOKS    0.0            0         NaN    1   \n",
       "\n",
       "            dayofyear  month  year      0     1      2      3      4      5  \\\n",
       "date                                                                          \n",
       "2013-01-01          1      1  2013  False  True  False  False  False  False   \n",
       "2013-01-01          1      1  2013  False  True  False  False  False  False   \n",
       "2013-01-01          1      1  2013  False  True  False  False  False  False   \n",
       "2013-01-01          1      1  2013  False  True  False  False  False  False   \n",
       "2013-01-01          1      1  2013  False  True  False  False  False  False   \n",
       "\n",
       "                6  \n",
       "date               \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_merged = pd.merge(\n",
    "    pd.concat([train_data, test_data]), oil, on=\"date\", how=\"left\"\n",
    ").set_index([\"date\"])\n",
    "\n",
    "future_merged['day'] = future_merged.index.day\n",
    "future_merged['dayofweek'] = future_merged.index.dayofweek\n",
    "future_merged['dayofyear'] = future_merged.index.dayofyear\n",
    "future_merged['month'] = future_merged.index.month\n",
    "future_merged['year'] = future_merged.index.year\n",
    "\n",
    "# Разбиваем день недели на столбцы, так как он нет линейной зависимости, только катеригоиальная\n",
    "day_of_week_dummies = pd.get_dummies(future_merged[\"dayofweek\"])\n",
    "\n",
    "future_merged = pd.concat([future_merged, day_of_week_dummies], axis=1)\n",
    "future_merged = future_merged.drop([\"dayofweek\"], axis=1)\n",
    "\n",
    "future_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd3193",
   "metadata": {},
   "source": [
    "### Скейлим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8706d194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:54.826675Z",
     "iopub.status.busy": "2023-10-18T07:35:54.826304Z",
     "iopub.status.idle": "2023-10-18T07:35:55.358068Z",
     "shell.execute_reply": "2023-10-18T07:35:55.356925Z"
    },
    "papermill": {
     "duration": 0.545927,
     "end_time": "2023-10-18T07:35:55.360446",
     "exception": false,
     "start_time": "2023-10-18T07:35:54.814519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  store_nbr      family  sales  onpromotion  dcoilwtico  day  \\\n",
       "date                                                                         \n",
       "2013-01-01   0          1  AUTOMOTIVE    0.0          0.0         NaN  0.0   \n",
       "2013-01-01   1          1   BABY CARE    0.0          0.0         NaN  0.0   \n",
       "2013-01-01   2          1      BEAUTY    0.0          0.0         NaN  0.0   \n",
       "2013-01-01   3          1   BEVERAGES    0.0          0.0         NaN  0.0   \n",
       "2013-01-01   4          1       BOOKS    0.0          0.0         NaN  0.0   \n",
       "\n",
       "            dayofyear  month  year      0     1      2      3      4      5  \\\n",
       "date                                                                          \n",
       "2013-01-01        0.0    0.0   0.0  False  True  False  False  False  False   \n",
       "2013-01-01        0.0    0.0   0.0  False  True  False  False  False  False   \n",
       "2013-01-01        0.0    0.0   0.0  False  True  False  False  False  False   \n",
       "2013-01-01        0.0    0.0   0.0  False  True  False  False  False  False   \n",
       "2013-01-01        0.0    0.0   0.0  False  True  False  False  False  False   \n",
       "\n",
       "                6  \n",
       "date               \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  \n",
       "2013-01-01  False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_cols = ['dcoilwtico', 'onpromotion','day','dayofyear','month','year']\n",
    "\n",
    "future_merged.columns = future_merged.columns.astype(str)\n",
    "future_merged[scaled_cols] = scaler.fit_transform(future_merged[scaled_cols])\n",
    "\n",
    "future_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fe1a8",
   "metadata": {},
   "source": [
    "### Разбиваем праздники на категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3f89bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:55.383288Z",
     "iopub.status.busy": "2023-10-18T07:35:55.382900Z",
     "iopub.status.idle": "2023-10-18T07:35:57.419075Z",
     "shell.execute_reply": "2023-10-18T07:35:57.418041Z"
    },
    "papermill": {
     "duration": 2.050507,
     "end_time": "2023-10-18T07:35:57.421231",
     "exception": false,
     "start_time": "2023-10-18T07:35:55.370724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>national_holiday</th>\n",
       "      <th>national_event</th>\n",
       "      <th>local_holiday</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>christmas</th>\n",
       "      <th>football</th>\n",
       "      <th>work_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  id  store_nbr      family  sales  onpromotion  dcoilwtico  day  \\\n",
       "0 2013-01-01   0          1  AUTOMOTIVE    0.0          0.0         NaN  0.0   \n",
       "1 2013-01-01   1          1   BABY CARE    0.0          0.0         NaN  0.0   \n",
       "2 2013-01-01   2          1      BEAUTY    0.0          0.0         NaN  0.0   \n",
       "3 2013-01-01   3          1   BEVERAGES    0.0          0.0         NaN  0.0   \n",
       "4 2013-01-01   4          1       BOOKS    0.0          0.0         NaN  0.0   \n",
       "\n",
       "   dayofyear  month  ...      4      5      6  national_holiday  \\\n",
       "0        0.0    0.0  ...  False  False  False               1.0   \n",
       "1        0.0    0.0  ...  False  False  False               1.0   \n",
       "2        0.0    0.0  ...  False  False  False               1.0   \n",
       "3        0.0    0.0  ...  False  False  False               1.0   \n",
       "4        0.0    0.0  ...  False  False  False               1.0   \n",
       "\n",
       "   national_event  local_holiday  earthquake  christmas  football  work_day  \n",
       "0             0.0            0.0         0.0        0.0       0.0       0.0  \n",
       "1             0.0            0.0         0.0        0.0       0.0       0.0  \n",
       "2             0.0            0.0         0.0        0.0       0.0       0.0  \n",
       "3             0.0            0.0         0.0        0.0       0.0       0.0  \n",
       "4             0.0            0.0         0.0        0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holiday_store_list = []\n",
    "\n",
    "def filter_column(data, column, value):\n",
    "    return np.where(data[column].str.contains(value), 1, 0)\n",
    "\n",
    "for i in range(len(stores)):\n",
    "    df_holiday_dummies = pd.DataFrame(columns=[\"date\"])\n",
    "    df_holiday_dummies[\"date\"] = holiday_events[\"date\"]\n",
    "    df_holiday_dummies[\"store_nbr\"] = i + 1\n",
    "\n",
    "    # Столбцы-классификаторы\n",
    "    df_holiday_dummies[\"national_holiday\"] = np.where(((holiday_events[\"type\"] == \"Holiday\") & (holiday_events[\"locale\"] == \"National\")), 1, 0)    \n",
    "    df_holiday_dummies[\"national_event\"] = np.where(((holiday_events[\"type\"] == \"Event\") & (holiday_events[\"locale\"] == \"National\") & (~holiday_events['description'].str.contains('Terremoto Manabi')) & (~holiday_events['description'].str.contains('futbol'))), 1, 0)    \n",
    "    df_holiday_dummies[\"local_holiday\"] = np.where(((holiday_events[\"type\"] == \"Holiday\") & ((holiday_events[\"locale_name\"] == stores['state'][i]) | (holiday_events[\"locale_name\"] == stores['city'][i]))), 1, 0)\n",
    "\n",
    "    # Землетрясение (продажи должны быть сильно ниже (?))\n",
    "    df_holiday_dummies[\"earthquake\"] = filter_column(holiday_events, \"description\", \"Terremoto Manabi\")\n",
    "\n",
    "    # Праздники с наибольшим влянием\n",
    "    df_holiday_dummies[\"christmas\"] = filter_column(holiday_events, \"description\", \"Navidad\")\n",
    "    df_holiday_dummies[\"football\"] = filter_column(\n",
    "        holiday_events, \"description\", \"futbol\"\n",
    "    )\n",
    "\n",
    "    # Рабочий день в праздник (продажи ниже (?))\n",
    "    df_holiday_dummies[\"work_day\"] = filter_column(holiday_events, \"type\", \"Work Day\")\n",
    "\n",
    "    df_holiday_dummies = df_holiday_dummies[~df_holiday_dummies['date'].duplicated(keep='first')]\n",
    "\n",
    "    holiday_store_list.append(df_holiday_dummies)\n",
    "\n",
    "holiday_store_df = pd.concat(holiday_store_list)\n",
    "\n",
    "future_merged = pd.merge(future_merged, holiday_store_df, on=['date','store_nbr'], how='left')\n",
    "future_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cf96f",
   "metadata": {
    "papermill": {
     "duration": 0.010218,
     "end_time": "2023-10-18T07:35:57.442119",
     "exception": false,
     "start_time": "2023-10-18T07:35:57.431901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Транзакции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba21ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:57.464735Z",
     "iopub.status.busy": "2023-10-18T07:35:57.464409Z",
     "iopub.status.idle": "2023-10-18T07:35:57.898531Z",
     "shell.execute_reply": "2023-10-18T07:35:57.897482Z"
    },
    "papermill": {
     "duration": 0.448161,
     "end_time": "2023-10-18T07:35:57.900796",
     "exception": false,
     "start_time": "2023-10-18T07:35:57.452635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>561</td>\n",
       "      <td>25</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>562</td>\n",
       "      <td>25</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>563</td>\n",
       "      <td>25</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>564</td>\n",
       "      <td>25</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>810.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>565</td>\n",
       "      <td>25</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  store_nbr      family  sales  onpromotion  transactions\n",
       "date                                                                    \n",
       "2013-01-01  561         25  AUTOMOTIVE    0.0            0      0.091573\n",
       "2013-01-01  562         25   BABY CARE    0.0            0      0.091573\n",
       "2013-01-01  563         25      BEAUTY    2.0            0      0.091573\n",
       "2013-01-01  564         25   BEVERAGES  810.0            0      0.091573\n",
       "2013-01-01  565         25       BOOKS    0.0            0      0.091573"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_merged = pd.merge(train_data, transcations, on=['date','store_nbr']).set_index('date')\n",
    "\n",
    "# Скейлим транзации от Min до Max\n",
    "past_merged['transactions'] = scaler.fit_transform(past_merged[['transactions']])\n",
    "\n",
    "past_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ed988",
   "metadata": {
    "papermill": {
     "duration": 0.01045,
     "end_time": "2023-10-18T07:35:57.922100",
     "exception": false,
     "start_time": "2023-10-18T07:35:57.911650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Разбиение на обучающую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037a15c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:57.946356Z",
     "iopub.status.busy": "2023-10-18T07:35:57.945581Z",
     "iopub.status.idle": "2023-10-18T07:35:58.286233Z",
     "shell.execute_reply": "2023-10-18T07:35:58.285294Z"
    },
    "papermill": {
     "duration": 0.355803,
     "end_time": "2023-10-18T07:35:58.288625",
     "exception": false,
     "start_time": "2023-10-18T07:35:57.932822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_static_cov, val_static_cov = static_merged.loc[static_merged.index <= '2017-07-30'], static_merged.loc[static_merged.index > '2017-07-30']\n",
    "\n",
    "train_past_cov = past_merged.loc[past_merged.index <= '2017-07-30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e325716",
   "metadata": {
    "papermill": {
     "duration": 0.011036,
     "end_time": "2023-10-18T07:35:58.571440",
     "exception": false,
     "start_time": "2023-10-18T07:35:58.560404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Конверт к TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4a3ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:35:58.595471Z",
     "iopub.status.busy": "2023-10-18T07:35:58.595124Z",
     "iopub.status.idle": "2023-10-18T07:36:25.272602Z",
     "shell.execute_reply": "2023-10-18T07:36:25.271227Z"
    },
    "papermill": {
     "duration": 26.69282,
     "end_time": "2023-10-18T07:36:25.275491",
     "exception": false,
     "start_time": "2023-10-18T07:35:58.582671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n"
     ]
    }
   ],
   "source": [
    "family_ts_dict = {}\n",
    "\n",
    "for family in family_list:\n",
    "    train_family = static_merged.loc[static_merged['family'] == family]\n",
    "    \n",
    "    family_ts_list = TimeSeries.from_group_dataframe(\n",
    "        df=train_family,\n",
    "        group_cols=['store_nbr', 'family'],\n",
    "        value_cols='sales',\n",
    "        static_cols=['city','state','type','cluster'],\n",
    "        fill_missing_dates=True,\n",
    "        freq='D',\n",
    "        fillna_value=0,\n",
    "    )\n",
    "    \n",
    "    family_ts_dict[family] = family_ts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46b21c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:36:25.299539Z",
     "iopub.status.busy": "2023-10-18T07:36:25.299150Z",
     "iopub.status.idle": "2023-10-18T07:36:44.897519Z",
     "shell.execute_reply": "2023-10-18T07:36:44.896408Z"
    },
    "papermill": {
     "duration": 19.613102,
     "end_time": "2023-10-18T07:36:44.899913",
     "exception": false,
     "start_time": "2023-10-18T07:36:25.286811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer, Scaler, MissingValuesFiller, InvertibleMapper\n",
    "from darts.dataprocessing import Pipeline\n",
    "\n",
    "family_pipeline_dict = {}\n",
    "family_ts_transformed_dict = {}\n",
    "\n",
    "for family in family_ts_dict:\n",
    "    static_cov_transformer = StaticCovariatesTransformer()\n",
    "    log_transformer = InvertibleMapper(np.log1p, np.expm1)\n",
    "    scaler = Scaler()\n",
    "    \n",
    "    train_pipeline = Pipeline([\n",
    "        static_cov_transformer,\n",
    "        log_transformer,\n",
    "        scaler\n",
    "    ])\n",
    "    \n",
    "    train_transformed = train_pipeline.fit_transform(family_ts_dict[family])\n",
    "    family_pipeline_dict[family] = train_pipeline\n",
    "    family_ts_transformed_dict[family] = train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5065e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:36:44.924146Z",
     "iopub.status.busy": "2023-10-18T07:36:44.923763Z",
     "iopub.status.idle": "2023-10-18T07:37:18.296359Z",
     "shell.execute_reply": "2023-10-18T07:37:18.295447Z"
    },
    "papermill": {
     "duration": 33.387661,
     "end_time": "2023-10-18T07:37:18.298816",
     "exception": false,
     "start_time": "2023-10-18T07:36:44.911155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "family_future_cov_dict = {}\n",
    "\n",
    "for family in family_list:\n",
    "    future_cov_family = future_merged.loc[future_merged['family'] == family]\n",
    "    \n",
    "    family_future_cov_list = TimeSeries.from_group_dataframe(\n",
    "        df=future_cov_family,\n",
    "        group_cols=['store_nbr', 'family'],\n",
    "        time_col='date',\n",
    "        value_cols=[\n",
    "            'onpromotion','dcoilwtico', 'day',\n",
    "            'dayofyear','month','year',\n",
    "            '0','1','2','3','4','5','6',\n",
    "            'national_holiday','earthquake','christmas',\n",
    "            'football','national_event','work_day',\n",
    "            'local_holiday'\n",
    "        ],\n",
    "        fill_missing_dates=True,\n",
    "        freq='D',\n",
    "    )\n",
    "\n",
    "    family_future_cov_dict[family] = family_future_cov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12edd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:37:18.323875Z",
     "iopub.status.busy": "2023-10-18T07:37:18.323485Z",
     "iopub.status.idle": "2023-10-18T07:37:39.824379Z",
     "shell.execute_reply": "2023-10-18T07:37:39.823144Z"
    },
    "papermill": {
     "duration": 21.516058,
     "end_time": "2023-10-18T07:37:39.827131",
     "exception": false,
     "start_time": "2023-10-18T07:37:18.311073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n",
      "UserWarning: `time_col` was not set and `df` has a monotonically increasing (time) index. This results in time series groups with non-overlapping (time) index. You can ignore this warning if the index represents the actual index of each individual time series group.\n"
     ]
    }
   ],
   "source": [
    "family_past_cov_dict = {}\n",
    "\n",
    "for family in family_list:\n",
    "    past_cov_family = past_merged.loc[past_merged['family'] == family]\n",
    "    \n",
    "    family_past_cov_list = TimeSeries.from_group_dataframe(\n",
    "        df=past_cov_family,\n",
    "        group_cols=['store_nbr', 'family'],\n",
    "        value_cols=['transactions'],\n",
    "        fill_missing_dates=True,\n",
    "        freq='D'\n",
    "    )\n",
    "    \n",
    "    family_past_cov_dict[family] = family_past_cov_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac5081",
   "metadata": {
    "papermill": {
     "duration": 0.010651,
     "end_time": "2023-10-18T07:37:39.871339",
     "exception": false,
     "start_time": "2023-10-18T07:37:39.860688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb1430d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:37:39.896119Z",
     "iopub.status.busy": "2023-10-18T07:37:39.894979Z",
     "iopub.status.idle": "2023-10-18T07:38:02.687448Z",
     "shell.execute_reply": "2023-10-18T07:38:02.686377Z"
    },
    "papermill": {
     "duration": 22.807187,
     "end_time": "2023-10-18T07:38:02.689918",
     "exception": false,
     "start_time": "2023-10-18T07:37:39.882731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/statsforecast/utils.py:237: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  \"ds\": pd.date_range(start=\"1949-01-01\", periods=len(AirPassengers), freq=\"M\"),\n"
     ]
    }
   ],
   "source": [
    "from darts.models import LightGBMModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(lags=7):\n",
    "    lgbm_model_dict = {}\n",
    "\n",
    "    for family in tqdm(family_list):\n",
    "        lgbm_model = LightGBMModel(\n",
    "            lags=lags, \n",
    "            lags_past_covariates=[-16,-17,-18,-19,-20,-21,-22],\n",
    "            lags_future_covariates=(14,1)\n",
    "        )\n",
    "\n",
    "        lgbm_model.fit(\n",
    "            series = family_ts_transformed_dict[family], \n",
    "            past_covariates=family_past_cov_dict[family], \n",
    "            future_covariates=family_future_cov_dict[family]\n",
    "        )\n",
    "\n",
    "        lgbm_model_dict[family] = lgbm_model\n",
    "        \n",
    "    return lgbm_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccebb350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:38:02.715169Z",
     "iopub.status.busy": "2023-10-18T07:38:02.714769Z",
     "iopub.status.idle": "2023-10-18T07:38:02.721818Z",
     "shell.execute_reply": "2023-10-18T07:38:02.720749Z"
    },
    "papermill": {
     "duration": 0.021845,
     "end_time": "2023-10-18T07:38:02.723741",
     "exception": false,
     "start_time": "2023-10-18T07:38:02.701896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_model(lgbm_model_dict):    \n",
    "    pred_dict = {}\n",
    "\n",
    "    for family in tqdm(family_list):\n",
    "        pred = lgbm_model_dict[family].predict(\n",
    "            n=16, \n",
    "            series=family_ts_transformed_dict[family], \n",
    "            past_covariates=family_past_cov_dict[family], \n",
    "            future_covariates=family_future_cov_dict[family]\n",
    "        )\n",
    "\n",
    "        pred_dict[family] = family_pipeline_dict[family].inverse_transform(pred)\n",
    "        \n",
    "    pred_df_list = []\n",
    "    for family in family_list:\n",
    "        for i, pred in enumerate(pred_dict[family]):\n",
    "            pred_df = pred.pd_dataframe()\n",
    "            pred_df['family'] = family\n",
    "            pred_df['store_nbr'] = i+1\n",
    "\n",
    "            pred_df_list.append(pred_df)\n",
    "\n",
    "    final_preds = pd.concat(pred_df_list)\n",
    "    \n",
    "    final_preds.loc[final_preds['sales'] < 0, 'sales'] = 0\n",
    "    \n",
    "    return final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cf69e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:38:02.769794Z",
     "iopub.status.busy": "2023-10-18T07:38:02.769434Z",
     "iopub.status.idle": "2023-10-18T07:38:02.774432Z",
     "shell.execute_reply": "2023-10-18T07:38:02.773414Z"
    },
    "papermill": {
     "duration": 0.041543,
     "end_time": "2023-10-18T07:38:02.776362",
     "exception": false,
     "start_time": "2023-10-18T07:38:02.734819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_predict_model(lags=7):\n",
    "    return predict_model(train_model(lags=lags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "880d8081",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:38:02.800714Z",
     "iopub.status.busy": "2023-10-18T07:38:02.799903Z",
     "iopub.status.idle": "2023-10-18T07:55:31.913622Z",
     "shell.execute_reply": "2023-10-18T07:55:31.912706Z"
    },
    "papermill": {
     "duration": 1049.128445,
     "end_time": "2023-10-18T07:55:31.916009",
     "exception": false,
     "start_time": "2023-10-18T07:38:02.787564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18999\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.493630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/33 [00:03<02:01,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13221\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.028012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/33 [00:05<01:25,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18983\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.380327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/33 [00:09<01:28,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20679\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.828335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 4/33 [00:12<01:35,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13516\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.015553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 5/33 [00:14<01:17,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20289\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.837519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 6/33 [00:18<01:22,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19089\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.331343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 7/33 [00:21<01:17,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20289\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.833296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 8/33 [00:24<01:21,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21279\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.844467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 9/33 [00:28<01:21,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20094\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.840530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 10/33 [00:32<01:21,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19359\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.777918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 11/33 [00:35<01:16,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19359\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.561314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 12/33 [00:39<01:14,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21714\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.838380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 13/33 [00:43<01:11,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18984\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.510620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 14/33 [00:46<01:07,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16011\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.228784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [00:49<01:00,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19239\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.387588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 16/33 [00:52<00:56,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19104\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.389545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 17/33 [00:55<00:51,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12663\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.137429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [00:58<00:45,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19554\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.531501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 19/33 [01:01<00:42,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19127\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.269634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 20/33 [01:04<00:38,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19089\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.231856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 21/33 [01:07<00:36,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19014\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.429777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 22/33 [01:10<00:34,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19179\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.529878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 23/33 [01:14<00:32,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18938\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.241319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 24/33 [01:17<00:28,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19719\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.815156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 25/33 [01:20<00:26,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19629\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.773414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 26/33 [01:24<00:24,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18938\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.281923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 27/33 [01:27<00:19,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19104\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.332931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 28/33 [01:30<00:15,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19599\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.784244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 29/33 [01:34<00:13,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19089\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.782810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [01:37<00:10,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 22614\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.591725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 31/33 [01:40<00:06,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19047\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.092722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 32/33 [01:43<00:03,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18984\n",
      "[LightGBM] [Info] Number of data points in the train set: 82851, number of used features: 343\n",
      "[LightGBM] [Info] Start training from score 0.550508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:46<00:00,  3.23s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  3%|▎         | 1/33 [00:00<00:19,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  6%|▌         | 2/33 [00:01<00:19,  1.55it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  9%|▉         | 3/33 [00:01<00:18,  1.58it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 12%|█▏        | 4/33 [00:02<00:23,  1.23it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 15%|█▌        | 5/33 [00:03<00:20,  1.35it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 18%|█▊        | 6/33 [00:04<00:18,  1.43it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 21%|██        | 7/33 [00:04<00:17,  1.50it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 24%|██▍       | 8/33 [00:05<00:16,  1.54it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 27%|██▋       | 9/33 [00:06<00:15,  1.58it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 30%|███       | 10/33 [00:06<00:14,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 33%|███▎      | 11/33 [00:07<00:13,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 36%|███▋      | 12/33 [00:07<00:13,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 39%|███▉      | 13/33 [00:08<00:12,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 42%|████▏     | 14/33 [00:09<00:11,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 45%|████▌     | 15/33 [00:09<00:11,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 48%|████▊     | 16/33 [00:10<00:10,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 52%|█████▏    | 17/33 [00:10<00:09,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 55%|█████▍    | 18/33 [00:11<00:09,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 58%|█████▊    | 19/33 [00:12<00:08,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 61%|██████    | 20/33 [00:12<00:08,  1.62it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 64%|██████▎   | 21/33 [00:13<00:09,  1.30it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 67%|██████▋   | 22/33 [00:14<00:08,  1.37it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 70%|██████▉   | 23/33 [00:15<00:06,  1.44it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 73%|███████▎  | 24/33 [00:15<00:05,  1.50it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 76%|███████▌  | 25/33 [00:16<00:05,  1.52it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 79%|███████▉  | 26/33 [00:17<00:04,  1.57it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 82%|████████▏ | 27/33 [00:17<00:03,  1.60it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 85%|████████▍ | 28/33 [00:18<00:03,  1.57it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 88%|████████▊ | 29/33 [00:18<00:02,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 91%|█████████ | 30/33 [00:19<00:01,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 94%|█████████▍| 31/33 [00:20<00:01,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 97%|█████████▋| 32/33 [00:20<00:00,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "100%|██████████| 33/33 [00:21<00:00,  1.54it/s]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34809\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.495629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/33 [00:05<02:45,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 17685\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.029010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/33 [00:07<01:47,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34731\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.382191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/33 [00:12<02:06,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36489\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.830911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 4/33 [00:18<02:22,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 18600\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.016107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 5/33 [00:20<01:50,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36099\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.838071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 6/33 [00:26<02:01,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34899\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.343155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 7/33 [00:30<01:54,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36099\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.833441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 8/33 [00:36<02:00,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37089\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.847717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 9/33 [00:42<02:07,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35904\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.841639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 10/33 [00:48<02:05,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35169\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.779176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 11/33 [00:53<01:58,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 35169\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.564580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 12/33 [01:00<02:00,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37524\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.838989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 13/33 [01:05<01:55,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34794\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.510547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 14/33 [01:10<01:44,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25892\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.229505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [01:14<01:31,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35049\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.401406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 16/33 [01:19<01:24,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34914\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.403433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 17/33 [01:24<01:18,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16011\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.137957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [01:27<01:04,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35364\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.550449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 19/33 [01:32<01:02,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34937\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.279246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 20/33 [01:36<00:55,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34899\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.234601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 21/33 [01:40<00:51,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34824\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.427216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 22/33 [01:44<00:48,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34989\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.531147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 23/33 [01:50<00:46,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.249922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 24/33 [01:54<00:39,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35529\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.815237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 25/33 [01:59<00:37,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35439\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.774404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 26/33 [02:06<00:37,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34686\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.291974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 27/33 [02:10<00:29,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34914\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.344800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 28/33 [02:15<00:24,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35409\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.786696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 29/33 [02:20<00:20,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34899\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.783416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [02:25<00:15,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38424\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.611696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 31/33 [02:30<00:10,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34795\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.096028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 32/33 [02:34<00:04,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34794\n",
      "[LightGBM] [Info] Number of data points in the train set: 79999, number of used features: 405\n",
      "[LightGBM] [Info] Start training from score 0.548367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [02:39<00:00,  4.83s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  3%|▎         | 1/33 [00:00<00:20,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  6%|▌         | 2/33 [00:01<00:18,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  9%|▉         | 3/33 [00:01<00:18,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 12%|█▏        | 4/33 [00:02<00:17,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 15%|█▌        | 5/33 [00:03<00:16,  1.67it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 18%|█▊        | 6/33 [00:03<00:16,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 21%|██        | 7/33 [00:04<00:15,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 24%|██▍       | 8/33 [00:04<00:15,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 27%|██▋       | 9/33 [00:05<00:14,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 30%|███       | 10/33 [00:06<00:13,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 33%|███▎      | 11/33 [00:06<00:13,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 36%|███▋      | 12/33 [00:07<00:12,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 39%|███▉      | 13/33 [00:07<00:12,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 42%|████▏     | 14/33 [00:08<00:11,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 45%|████▌     | 15/33 [00:09<00:10,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 48%|████▊     | 16/33 [00:09<00:10,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 52%|█████▏    | 17/33 [00:10<00:09,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 55%|█████▍    | 18/33 [00:11<00:11,  1.29it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 58%|█████▊    | 19/33 [00:12<00:10,  1.38it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 61%|██████    | 20/33 [00:12<00:09,  1.44it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 64%|██████▎   | 21/33 [00:13<00:08,  1.49it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 67%|██████▋   | 22/33 [00:13<00:07,  1.54it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 70%|██████▉   | 23/33 [00:14<00:06,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 73%|███████▎  | 24/33 [00:15<00:05,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 76%|███████▌  | 25/33 [00:15<00:04,  1.62it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 79%|███████▉  | 26/33 [00:16<00:04,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 82%|████████▏ | 27/33 [00:16<00:03,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 85%|████████▍ | 28/33 [00:17<00:03,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 88%|████████▊ | 29/33 [00:18<00:02,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 91%|█████████ | 30/33 [00:18<00:01,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 94%|█████████▍| 31/33 [00:19<00:01,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 97%|█████████▋| 32/33 [00:19<00:00,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "100%|██████████| 33/33 [00:20<00:00,  1.60it/s]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.251826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 57504\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.497985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/33 [00:07<04:08,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 24093\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.030588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/33 [00:10<02:26,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57337\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.385773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/33 [00:16<02:46,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.282583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59184\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.834684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 4/33 [00:25<03:15,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25898\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.016983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 5/33 [00:27<02:24,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58794\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.838614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 6/33 [00:36<02:48,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57594\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.361816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 7/33 [00:42<02:41,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58794\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.833740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 8/33 [00:50<02:49,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59784\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.852889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 9/33 [00:58<02:52,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58599\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.842992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 10/33 [01:06<02:55,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.269456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 57864\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.780851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 11/33 [01:15<02:51,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57864\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.567412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 12/33 [01:23<02:47,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60219\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.839624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 13/33 [01:31<02:41,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57489\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.509949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 14/33 [01:39<02:28,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39752\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.231663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [01:44<02:07,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57744\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.423235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 16/33 [01:51<02:00,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57609\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.425372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 17/33 [01:58<01:52,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.192522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20713\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.134927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [02:01<01:29,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58059\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.580383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 19/33 [02:08<01:27,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57632\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.294432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 20/33 [02:14<01:17,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57594\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.238747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 21/33 [02:20<01:11,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57519\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.423893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 22/33 [02:27<01:10,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.262137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 57684\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.533349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 23/33 [02:35<01:07,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57292\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.263513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 24/33 [02:40<00:57,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.245385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 58224\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.814878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 25/33 [02:48<00:55,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58134\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.775887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 26/33 [02:56<00:50,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57302\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.307852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 27/33 [03:02<00:40,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57609\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.363550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 28/33 [03:08<00:32,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.242084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 58104\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.790364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 29/33 [03:16<00:28,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.236116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 57594\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.784711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [03:24<00:21,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61119\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.638985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 31/33 [03:31<00:14,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57443\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.101250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 32/33 [03:35<00:06,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.289876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 57489\n",
      "[LightGBM] [Info] Number of data points in the train set: 75873, number of used features: 494\n",
      "[LightGBM] [Info] Start training from score 0.546165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [03:45<00:00,  6.82s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  3%|▎         | 1/33 [00:00<00:19,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  6%|▌         | 2/33 [00:01<00:18,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  9%|▉         | 3/33 [00:01<00:18,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 12%|█▏        | 4/33 [00:02<00:17,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 15%|█▌        | 5/33 [00:03<00:16,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 18%|█▊        | 6/33 [00:03<00:16,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 21%|██        | 7/33 [00:04<00:16,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 24%|██▍       | 8/33 [00:05<00:18,  1.38it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 27%|██▋       | 9/33 [00:06<00:20,  1.20it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 30%|███       | 10/33 [00:08<00:25,  1.12s/it]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 33%|███▎      | 11/33 [00:09<00:24,  1.13s/it]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 36%|███▋      | 12/33 [00:10<00:23,  1.12s/it]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 39%|███▉      | 13/33 [00:11<00:22,  1.10s/it]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 42%|████▏     | 14/33 [00:12<00:18,  1.04it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 45%|████▌     | 15/33 [00:12<00:15,  1.15it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 48%|████▊     | 16/33 [00:13<00:13,  1.27it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 52%|█████▏    | 17/33 [00:13<00:11,  1.34it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 55%|█████▍    | 18/33 [00:14<00:10,  1.40it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 58%|█████▊    | 19/33 [00:15<00:12,  1.16it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 61%|██████    | 20/33 [00:16<00:10,  1.26it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 64%|██████▎   | 21/33 [00:17<00:08,  1.36it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 67%|██████▋   | 22/33 [00:17<00:07,  1.42it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 70%|██████▉   | 23/33 [00:18<00:06,  1.46it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 73%|███████▎  | 24/33 [00:18<00:05,  1.52it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 76%|███████▌  | 25/33 [00:19<00:05,  1.53it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 79%|███████▉  | 26/33 [00:20<00:04,  1.56it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 82%|████████▏ | 27/33 [00:20<00:03,  1.60it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 85%|████████▍ | 28/33 [00:21<00:03,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 88%|████████▊ | 29/33 [00:21<00:02,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 91%|█████████ | 30/33 [00:22<00:01,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 94%|█████████▍| 31/33 [00:23<00:01,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 97%|█████████▋| 32/33 [00:23<00:00,  1.67it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "100%|██████████| 33/33 [00:24<00:00,  1.35it/s]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.714796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104132\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.506840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/33 [00:11<06:21, 11.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36581\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.034499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/33 [00:15<03:30,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 103862\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.394516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/33 [00:25<04:13,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.413336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 105812\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.844188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 4/33 [00:39<05:02, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35176\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 619\n",
      "[LightGBM] [Info] Start training from score 0.019154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 5/33 [00:41<03:30,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.430910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 105422\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.841427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 6/33 [00:54<04:11,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104222\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.408076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 7/33 [01:03<04:05,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.423772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 105422\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.835281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 8/33 [01:16<04:22, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.720178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106412\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.862917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 9/33 [01:29<04:31, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 105227\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.847114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 10/33 [01:42<04:31, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.524570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104492\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.784695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 11/33 [01:54<04:20, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.519738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104492\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.570750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 12/33 [02:07<04:14, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.454670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106847\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.841046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 13/33 [02:19<04:04, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.433024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104117\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.508362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 14/33 [02:31<03:50, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 67403\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.236133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 15/33 [02:39<03:14, 10.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104372\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.477347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 16/33 [02:50<03:04, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104237\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.479757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 17/33 [03:00<02:52, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.180048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 30192\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.130754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 18/33 [03:05<02:12,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104687\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.654587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 19/33 [03:16<02:11,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104260\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.332076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 20/33 [03:23<01:55,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104222\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.248724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 21/33 [03:33<01:48,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104147\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.416994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 22/33 [03:44<01:47,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.465331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104312\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.537499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 23/33 [03:56<01:42, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 103737\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.297204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 24/33 [04:03<01:25,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.485093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104852\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.814751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 25/33 [04:16<01:23, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.485089 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104762\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.779913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 26/33 [04:29<01:18, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 103930\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.347212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 27/33 [04:37<01:01, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.098750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104237\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.410032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 28/33 [04:47<00:51, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.510311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104732\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.795929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 29/33 [05:01<00:44, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.455582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104222\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.789148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 30/33 [05:13<00:34, 11.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.453248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 107747\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.706943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 31/33 [05:26<00:23, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.233437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 104042\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.114195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 32/33 [05:32<00:10, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.488247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 104117\n",
      "[LightGBM] [Info] Number of data points in the train set: 67272, number of used features: 677\n",
      "[LightGBM] [Info] Start training from score 0.556331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [05:45<00:00, 10.46s/it]\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  3%|▎         | 1/33 [00:00<00:19,  1.66it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  6%|▌         | 2/33 [00:01<00:18,  1.68it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "  9%|▉         | 3/33 [00:01<00:17,  1.68it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 12%|█▏        | 4/33 [00:02<00:17,  1.68it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 15%|█▌        | 5/33 [00:03<00:17,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 18%|█▊        | 6/33 [00:03<00:17,  1.57it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 21%|██        | 7/33 [00:04<00:16,  1.58it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 24%|██▍       | 8/33 [00:04<00:15,  1.60it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 27%|██▋       | 9/33 [00:05<00:14,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 30%|███       | 10/33 [00:06<00:14,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 33%|███▎      | 11/33 [00:06<00:13,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 36%|███▋      | 12/33 [00:07<00:12,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 39%|███▉      | 13/33 [00:07<00:12,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 42%|████▏     | 14/33 [00:08<00:11,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 45%|████▌     | 15/33 [00:09<00:10,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 48%|████▊     | 16/33 [00:09<00:10,  1.62it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 52%|█████▏    | 17/33 [00:10<00:09,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 55%|█████▍    | 18/33 [00:11<00:09,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 58%|█████▊    | 19/33 [00:12<00:11,  1.25it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 61%|██████    | 20/33 [00:12<00:09,  1.35it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 64%|██████▎   | 21/33 [00:13<00:08,  1.40it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 67%|██████▋   | 22/33 [00:14<00:07,  1.46it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 70%|██████▉   | 23/33 [00:14<00:06,  1.49it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 73%|███████▎  | 24/33 [00:15<00:05,  1.55it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 76%|███████▌  | 25/33 [00:15<00:05,  1.59it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 79%|███████▉  | 26/33 [00:16<00:04,  1.62it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 82%|████████▏ | 27/33 [00:17<00:03,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 85%|████████▍ | 28/33 [00:17<00:03,  1.65it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 88%|████████▊ | 29/33 [00:18<00:02,  1.63it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 91%|█████████ | 30/33 [00:18<00:01,  1.64it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 94%|█████████▍| 31/33 [00:19<00:01,  1.62it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      " 97%|█████████▋| 32/33 [00:20<00:00,  1.61it/s]`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "100%|██████████| 33/33 [00:20<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_month = train_predict_model(lags=31)\n",
    "pred_three_month = train_predict_model(lags=93)\n",
    "pred_half_year = train_predict_model(lags=365//2)\n",
    "pred_year = train_predict_model(lags=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a70d16",
   "metadata": {
    "papermill": {
     "duration": 0.021206,
     "end_time": "2023-10-18T07:55:32.095780",
     "exception": false,
     "start_time": "2023-10-18T07:55:32.074574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Собираем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86be2319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:55:32.150808Z",
     "iopub.status.busy": "2023-10-18T07:55:32.150335Z",
     "iopub.status.idle": "2023-10-18T07:55:32.159945Z",
     "shell.execute_reply": "2023-10-18T07:55:32.158698Z"
    },
    "papermill": {
     "duration": 0.040383,
     "end_time": "2023-10-18T07:55:32.162038",
     "exception": false,
     "start_time": "2023-10-18T07:55:32.121655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pred_month.copy()\n",
    "predictions[\"sales\"] = (\n",
    "    pred_month[\"sales\"]\n",
    "    + pred_three_month[\"sales\"]\n",
    "    + pred_half_year[\"sales\"]\n",
    "    + pred_year[\"sales\"]\n",
    ") / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42c59947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined RMSLE :  0.5017861540029763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "actual = val_static_cov.sort_values(['store_nbr', 'family', 'date'])['sales']\n",
    "preds = predictions.sort_values(['store_nbr', 'family', 'date'])['sales']\n",
    "\n",
    "score = np.sqrt(mean_squared_log_error(actual, preds))\n",
    "print('combined RMSLE : ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7328a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T07:55:32.210492Z",
     "iopub.status.busy": "2023-10-18T07:55:32.209202Z",
     "iopub.status.idle": "2023-10-18T07:55:32.314657Z",
     "shell.execute_reply": "2023-10-18T07:55:32.313380Z"
    },
    "papermill": {
     "duration": 0.134188,
     "end_time": "2023-10-18T07:55:32.319483",
     "exception": false,
     "start_time": "2023-10-18T07:55:32.185295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit = pd.merge(test_data, predictions, on=['store_nbr', 'family','date'])\n",
    "submit = submit.reindex(columns=['id','sales'])\n",
    "submit.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1215.938111,
   "end_time": "2023-10-18T07:55:36.187836",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-18T07:35:20.249725",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
